{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remodel for Various Districts in LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'regression.csv'\n",
    "path2 = 'classification.csv'\n",
    "merged_regression = pd.read_csv(path1, sep = '\\t')\n",
    "merged_classification = pd.read_csv(path2, sep = '\\t')\n",
    "merged_regression = merged_regression.drop(columns = ['Unnamed: 0'])\n",
    "merged_classification = merged_classification.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_df = df[['latitude', 'longitude', 'zipcode']]\n",
    "zipcode_df = zipcode_df.applymap(nullify)\n",
    "zipcode_df = zipcode_df.dropna(axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_classification = merged_classification.merge(zipcode_df, left_on = ['latitude', 'longitude'], \n",
    "                                                    right_on = ['latitude', 'longitude'], how = 'inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_class, Test_class = train_test_split(merged_classification, test_size = 0.20)\n",
    "X_train_2 = Train_class.drop(columns = ['price', 'review_scores_rating'])\n",
    "Y_train_2 = Train_class['price']\n",
    "\n",
    "X_test_2 = Test_class.drop(columns = ['price', 'review_scores_rating'])\n",
    "Y_test_2 = Test_class['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_class = Test_class.reset_index(drop = True)\n",
    "geo_data_test = Test_class[['latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "HancockPark = ['90066','90291','90292', '90015']\n",
    "Central = ['90034','90035','90019']\n",
    "Westwood = ['90036','90048','90069','90046']\n",
    "Hollywood = ['90028','90068','90027','90039','90029','90004','90038']\n",
    "MidCityWest = ['90005','90006','90015', '90017', '90012']\n",
    "MarVista = ['90065','90042']\n",
    "Balabala = ['90024','90025']\n",
    "\n",
    "class1 = Test_class.loc[Test_class['zipcode'].isin(HancockPark)]\n",
    "class2 = Test_class.loc[Test_class['zipcode'].isin(Central)]\n",
    "class3 = Test_class.loc[Test_class['zipcode'].isin(Westwood)]\n",
    "class4 = Test_class.loc[Test_class['zipcode'].isin(Hollywood)]\n",
    "class5 = Test_class.loc[Test_class['zipcode'].isin(MidCityWest)]\n",
    "class6 = Test_class.loc[Test_class['zipcode'].isin(MarVista)]\n",
    "class7 = Test_class.loc[Test_class['zipcode'].isin(Balabala)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train_2.drop(columns = ['zipcode'])\n",
    "Y_train_2 = Y_train_2.drop(columns = ['zipcode'])\n",
    "X_test_2 = X_test_2.drop(columns = ['zipcode'])\n",
    "Y_test_2 = Y_test_2.drop(columns = ['zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_col = list(merged_classification.columns)\n",
    "class1 = class1[classif_col]\n",
    "class2 = class2[classif_col]\n",
    "class3 = class3[classif_col]\n",
    "class4 = class4[classif_col]\n",
    "class5 = class5[classif_col]\n",
    "class6 = class6[classif_col]\n",
    "class7 = class7[classif_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.75, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_log.fit(X_train_2, Y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8443047337278107, 0.753968253968254, 0.7481481481481481, 0.7510469257563305)"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pred = clf_log.predict(X_test_2)\n",
    "\n",
    "acc = accuracy_score(Y_test_2, log_pred)\n",
    "precision = precision_score(Y_test_2, log_pred, average = None)\n",
    "recall = recall_score(Y_test_2, log_pred, average = None)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.776536312849162,\n",
       " 0.5464202064428045,\n",
       " 0.44822230697516735,\n",
       " 0.4924738731868802)"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_X = class1.drop(columns = ['price', 'review_scores_rating','zipcode'])\n",
    "class1_Y = class1['price']\n",
    "\n",
    "class1_pred = clf_log.predict(class1_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class1_Y, class1_pred)\n",
    "precision = precision_score(class1_Y, class1_pred, average = None)\n",
    "recall = recall_score(class1_Y, class1_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8505747126436781,\n",
       " 0.3701298701298701,\n",
       " 0.3166491043203372,\n",
       " 0.34130716349506823)"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2_X = class2.drop(columns = ['price', 'review_scores_rating','zipcode'])\n",
    "class2_Y = class2['price']\n",
    "\n",
    "class2_pred = clf_log.predict(class2_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class2_Y, class2_pred)\n",
    "precision = precision_score(class2_Y, class2_pred, average = None)\n",
    "recall = recall_score(class2_Y, class2_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8148148148148148,\n",
       " 0.6279184944106411,\n",
       " 0.46270575761501076,\n",
       " 0.5327985365025953)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class3_X = class3.drop(columns = ['price', 'review_scores_rating','zipcode'])\n",
    "class3_Y = class3['price']\n",
    "\n",
    "class3_pred = clf_log.predict(class3_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class3_Y, class3_pred)\n",
    "precision = precision_score(class3_Y, class3_pred, average = None)\n",
    "recall = recall_score(class3_Y, class3_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8697788697788698, 0.5293650793650794, 0.4993100214362272, 0.513898487325051)"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class4_X = class4.drop(columns = ['price', 'review_scores_rating','zipcode'])\n",
    "class4_Y = class4['price']\n",
    "\n",
    "class4_pred = clf_log.predict(class4_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class4_Y, class4_pred)\n",
    "precision = precision_score(class4_Y, class4_pred, average = None)\n",
    "recall = recall_score(class4_Y, class4_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7762237762237763,\n",
       " 0.3457259953161592,\n",
       " 0.3312003530450133,\n",
       " 0.3383073268835353)"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class5_X = class5.drop(columns = ['price', 'review_scores_rating','zipcode'])\n",
    "class5_Y = class5['price']\n",
    "\n",
    "class5_pred = clf_log.predict(class5_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class5_Y, class5_pred)\n",
    "precision = precision_score(class5_Y, class5_pred, average = None)\n",
    "recall = recall_score(class5_Y, class5_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9354838709677419,\n",
       " 0.8564814814814814,\n",
       " 0.8564814814814814,\n",
       " 0.8564814814814814)"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class6_X = class6.drop(columns = ['price', 'review_scores_rating','zipcode'])\n",
    "class6_Y = class6['price']\n",
    "\n",
    "class6_pred = clf_log.predict(class6_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class6_Y, class6_pred)\n",
    "precision = precision_score(class6_Y, class6_pred, average = None)\n",
    "recall = recall_score(class6_Y, class6_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85, 0.8296703296703296, 0.8375, 0.8335667792700008)"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class7_X = class7.drop(columns = ['price', 'review_scores_rating','zipcode'])\n",
    "class7_Y = class7['price']\n",
    "\n",
    "class7_pred = clf_log.predict(class7_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class7_Y, class7_pred)\n",
    "precision = precision_score(class7_Y, class7_pred, average = None)\n",
    "recall = recall_score(class7_Y, class7_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=6) \n",
    "knn.fit(X_train_2, Y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7899408284023669,\n",
       " 0.8564814814814814,\n",
       " 0.8564814814814814,\n",
       " 0.8564814814814814)"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pred = knn.predict(X_test_2)\n",
    "\n",
    "acc = accuracy_score(Y_test_2, knn_pred)\n",
    "precision = precision_score(Y_test_2, knn_pred, average = None)\n",
    "recall = recall_score(Y_test_2, knn_pred, average = None)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.659217877094972,\n",
       " 0.39376607553810744,\n",
       " 0.3418753707941351,\n",
       " 0.36599058889877467)"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_X = class1.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "class1_Y = class1['price']\n",
    "\n",
    "class1_pred = knn.predict(class1_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class1_Y, class1_pred)\n",
    "precision = precision_score(class1_Y, class1_pred, average = None)\n",
    "recall = recall_score(class1_Y, class1_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8160919540229885,\n",
       " 0.4155982905982906,\n",
       " 0.38742536002809974,\n",
       " 0.40101762192560275)"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2_X = class2.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "class2_Y = class2['price']\n",
    "\n",
    "class2_pred = knn.predict(class2_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class2_Y, class2_pred)\n",
    "precision = precision_score(class2_Y, class2_pred, average = None)\n",
    "recall = recall_score(class2_Y, class2_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7407407407407407,\n",
       " 0.5737639553429027,\n",
       " 0.3928093380733747,\n",
       " 0.46634816220096376)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class3_X = class3.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "class3_Y = class3['price']\n",
    "\n",
    "class3_pred = knn.predict(class3_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class3_Y, class3_pred)\n",
    "precision = precision_score(class3_Y, class3_pred, average = None)\n",
    "recall = recall_score(class3_Y, class3_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8083538083538083,\n",
       " 0.3578359125521985,\n",
       " 0.34338826366559483,\n",
       " 0.35046325228332914)"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class4_X = class4.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "class4_Y = class4['price']\n",
    "\n",
    "class4_pred = knn.predict(class4_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class4_Y, class4_pred)\n",
    "precision = precision_score(class4_Y, class4_pred, average = None)\n",
    "recall = recall_score(class4_Y, class4_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7552447552447552,\n",
       " 0.3403013582342954,\n",
       " 0.3187702265372168,\n",
       " 0.3291840933875982)"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class5_X = class5.drop(columns = ['price', 'review_scores_rating','zipcode'])\n",
    "class5_Y = class5['price']\n",
    "\n",
    "class5_pred = knn.predict(class5_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class5_Y, class5_pred)\n",
    "precision = precision_score(class5_Y, class5_pred, average = None)\n",
    "recall = recall_score(class5_Y, class5_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8548387096774194,\n",
       " 0.4344262295081967,\n",
       " 0.49074074074074076,\n",
       " 0.4608695652173913)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class6_X = class6.drop(columns = ['price', 'review_scores_rating','zipcode'])\n",
    "class6_Y = class6['price']\n",
    "\n",
    "class6_pred = knn.predict(class6_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class6_Y, class6_pred)\n",
    "precision = precision_score(class6_Y, class6_pred, average = None)\n",
    "recall = recall_score(class6_Y, class6_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.7291325695581015, 0.675, 0.7010228166797797)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class7_X = class7.drop(columns = ['price', 'review_scores_rating','zipcode'])\n",
    "class7_Y = class7['price']\n",
    "\n",
    "class7_pred = knn.predict(class7_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class7_Y, class7_pred)\n",
    "precision = precision_score(class7_Y, class7_pred, average = None)\n",
    "recall = recall_score(class7_Y, class7_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcf = RandomForestClassifier(n_estimators = 60)\n",
    "rcf.fit(X_train_2, Y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8480029585798816, 0.7291325695581015, 0.675, 0.7010228166797797)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred = rcf.predict(X_test_2)\n",
    "\n",
    "acc = accuracy_score(Y_test_2, rf_pred)\n",
    "precision = precision_score(Y_test_2, rf_pred, average = None)\n",
    "recall = recall_score(Y_test_2, rf_pred, average = None)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7486033519553073, 0.5951527469820154, 0.4773370624629206, 0.529773731105496)"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_X = class1.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "class1_Y = class1['price']\n",
    "\n",
    "class1_pred = rcf.predict(class1_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class1_Y, class1_pred)\n",
    "precision = precision_score(class1_Y, class1_pred, average = None)\n",
    "recall = recall_score(class1_Y, class1_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8850574712643678, 0.52019669827889, 0.52019669827889, 0.52019669827889)"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2_X = class2.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "class2_Y = class2['price']\n",
    "\n",
    "class2_pred = rcf.predict(class2_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class2_Y, class2_pred)\n",
    "precision = precision_score(class2_Y, class2_pred, average = None)\n",
    "recall = recall_score(class2_Y, class2_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8148148148148148,\n",
       " 0.5790896159317211,\n",
       " 0.46270575761501076,\n",
       " 0.5143967928259442)"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class3_X = class3.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "class3_Y = class3['price']\n",
    "\n",
    "class3_pred = rcf.predict(class3_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class3_Y, class3_pred)\n",
    "precision = precision_score(class3_Y, class3_pred, average = None)\n",
    "recall = recall_score(class3_Y, class3_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8771498771498771,\n",
       " 0.5513807439455138,\n",
       " 0.4970793140407288,\n",
       " 0.5228238498701093)"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class4_X = class4.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "class4_Y = class4['price']\n",
    "\n",
    "class4_pred = rcf.predict(class4_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class4_Y, class4_pred)\n",
    "precision = precision_score(class4_Y, class4_pred, average = None)\n",
    "recall = recall_score(class4_Y, class4_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8391608391608392,\n",
       " 0.5162037037037037,\n",
       " 0.4437702265372168,\n",
       " 0.4772542822583792)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class5_X = class5.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "class5_Y = class5['price']\n",
    "\n",
    "class5_pred = rcf.predict(class5_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class5_Y, class5_pred)\n",
    "precision = precision_score(class5_Y, class5_pred, average = None)\n",
    "recall = recall_score(class5_Y, class5_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9193548387096774,\n",
       " 0.8298701298701299,\n",
       " 0.7939814814814814,\n",
       " 0.8115292192284479)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class6_X = class6.drop(columns = ['price', 'review_scores_rating','zipcode'])\n",
    "class6_Y = class6['price']\n",
    "\n",
    "class6_pred = rcf.predict(class6_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class6_Y, class6_pred)\n",
    "precision = precision_score(class6_Y, class6_pred, average = None)\n",
    "recall = recall_score(class6_Y, class6_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8666666666666667, 0.84688995215311, 0.8625, 0.8546237010601448)"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class7_X = class7.drop(columns = ['price', 'review_scores_rating','zipcode'])\n",
    "class7_Y = class7['price']\n",
    "\n",
    "class7_pred = rcf.predict(class7_X)\n",
    "\n",
    "\n",
    "acc = accuracy_score(class7_Y, class7_pred)\n",
    "precision = precision_score(class7_Y, class7_pred, average = None)\n",
    "recall = recall_score(class7_Y, class7_pred, average = None)\n",
    "\n",
    "m_pre = sum(precision)/len(precision)\n",
    "m_rec = sum(recall)/len(recall)\n",
    "f1 = 2*m_pre*m_rec/(m_pre+m_rec)\n",
    "acc, m_pre, m_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_regression = merged_regression.merge(zipcode_df, left_on = ['latitude', 'longitude'], \n",
    "                                            right_on = ['latitude', 'longitude'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_reg, Test_reg = train_test_split(merged_regression, test_size = 0.20)\n",
    "X_train = Train_reg.drop(columns = ['price', 'review_scores_rating'])\n",
    "Y_train = Train_reg['price']\n",
    "\n",
    "X_test = Test_reg.drop(columns = ['price', 'review_scores_rating'])\n",
    "Y_test = Test_reg['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "HancockPark = ['90066','90291','90292', '90015', '90024','90025']\n",
    "Central = ['90034','90035','90019']\n",
    "Westwood = ['90036','90048','90069','90046']\n",
    "Hollywood = ['90028','90068','90027','90039','90029','90004','90038']\n",
    "MidCityWest = ['90005','90006','90015', '90017', '90012']\n",
    "MarVista = ['90065','90042']\n",
    "\n",
    "reg1 = Test_reg.loc[Test_reg['zipcode'].isin(HancockPark)]\n",
    "reg2 = Test_reg.loc[Test_reg['zipcode'].isin(Central)]\n",
    "reg3 = Test_reg.loc[Test_reg['zipcode'].isin(Westwood)]\n",
    "reg4 = Test_reg.loc[Test_reg['zipcode'].isin(Hollywood)]\n",
    "reg5 = Test_reg.loc[Test_reg['zipcode'].isin(MidCityWest)]\n",
    "reg6 = Test_reg.loc[Test_reg['zipcode'].isin(MarVista)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = ['zipcode'])\n",
    "Y_train = Y_train.drop(columns = ['zipcode'])\n",
    "X_test = X_test.drop(columns = ['zipcode'])\n",
    "Y_test = Y_test.drop(columns = ['zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_col = list(merged_regression.columns)\n",
    "reg1 = reg1[reg_col]\n",
    "reg2 = reg2[reg_col]\n",
    "reg3 = reg3[reg_col]\n",
    "reg4 = reg4[reg_col]\n",
    "reg5 = reg5[reg_col]\n",
    "reg6 = reg6[reg_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6862063956095232, 2809.8384290953027, 0.6862392481761099)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_pred = linear.predict(X_test)\n",
    "\n",
    "score_r2 = r2_score(Y_test, linear_pred)\n",
    "score_mean_sq_error = mean_squared_error(Y_test, linear_pred)\n",
    "score_ex_var = explained_variance_score(Y_test, linear_pred)\n",
    "\n",
    "score_r2, score_mean_sq_error, score_ex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7627230320486573, 1582.589032403901, 0.7759989732186293)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg1_X = reg1.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "reg1_Y = reg1['price']\n",
    "\n",
    "reg1_pred = linear.predict(reg1_X)\n",
    "\n",
    "\n",
    "score_r2 = r2_score(reg1_Y, reg1_pred)\n",
    "score_mean_sq_error = mean_squared_error(reg1_Y, reg1_pred)\n",
    "score_ex_var = explained_variance_score(reg1_Y, reg1_pred)\n",
    "\n",
    "score_r2, score_mean_sq_error, score_ex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5625934994367183, 4656.363759834345, 0.577966933330634)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2_X = reg2.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "reg2_Y = reg2['price']\n",
    "\n",
    "reg2_pred = linear.predict(reg2_X)\n",
    "\n",
    "\n",
    "score_r2 = r2_score(reg2_Y, reg2_pred)\n",
    "score_mean_sq_error = mean_squared_error(reg2_Y, reg2_pred)\n",
    "score_ex_var = explained_variance_score(reg2_Y, reg2_pred)\n",
    "\n",
    "score_r2, score_mean_sq_error, score_ex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5999252147993328, 2633.21136168841, 0.6000864495753495)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg3_X = reg3.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "reg3_Y = reg3['price']\n",
    "\n",
    "reg3_pred = linear.predict(reg3_X)\n",
    "\n",
    "\n",
    "score_r2 = r2_score(reg3_Y, reg3_pred)\n",
    "score_mean_sq_error = mean_squared_error(reg3_Y, reg3_pred)\n",
    "score_ex_var = explained_variance_score(reg3_Y, reg3_pred)\n",
    "\n",
    "score_r2, score_mean_sq_error, score_ex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7096357813697898, 2160.9757048354163, 0.7108886882376)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg4_X = reg4.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "reg4_Y = reg4['price']\n",
    "\n",
    "reg4_pred = linear.predict(reg4_X)\n",
    "\n",
    "\n",
    "score_r2 = r2_score(reg4_Y, reg4_pred)\n",
    "score_mean_sq_error = mean_squared_error(reg4_Y, reg4_pred)\n",
    "score_ex_var = explained_variance_score(reg4_Y, reg4_pred)\n",
    "\n",
    "score_r2, score_mean_sq_error, score_ex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.642676025064395, 3179.248886197938, 0.6460340957328767)"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg5_X = reg5.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "reg5_Y = reg5['price']\n",
    "\n",
    "reg5_pred = linear.predict(reg5_X)\n",
    "\n",
    "\n",
    "score_r2 = r2_score(reg5_Y, reg5_pred)\n",
    "score_mean_sq_error = mean_squared_error(reg5_Y, reg5_pred)\n",
    "score_ex_var = explained_variance_score(reg5_Y, reg5_pred)\n",
    "\n",
    "score_r2, score_mean_sq_error, score_ex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = 2).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.685661575893657, 2814.716971401936, 0.6856955850199531)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_pred = ridge.predict(X_test)\n",
    "\n",
    "score_r2 = r2_score(Y_test, ridge_pred)\n",
    "score_mean_sq_error = mean_squared_error(Y_test, ridge_pred)\n",
    "score_ex_var = explained_variance_score(Y_test, ridge_pred)\n",
    "\n",
    "score_r2, score_mean_sq_error, score_ex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7634323878979289, 1577.8577734164762, 0.7774239578077372)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg1_X = reg1.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "reg1_Y = reg1['price']\n",
    "\n",
    "reg1_pred = ridge.predict(reg1_X)\n",
    "\n",
    "\n",
    "score_r2 = r2_score(reg1_Y, reg1_pred)\n",
    "score_mean_sq_error = mean_squared_error(reg1_Y, reg1_pred)\n",
    "score_ex_var = explained_variance_score(reg1_Y, reg1_pred)\n",
    "\n",
    "score_r2, score_mean_sq_error, score_ex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5620978716728738, 4661.639911777586, 0.5775242372325629)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2_X = reg2.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "reg2_Y = reg2['price']\n",
    "\n",
    "reg2_pred = ridge.predict(reg2_X)\n",
    "\n",
    "\n",
    "score_r2 = r2_score(reg2_Y, reg2_pred)\n",
    "score_mean_sq_error = mean_squared_error(reg2_Y, reg2_pred)\n",
    "score_ex_var = explained_variance_score(reg2_Y, reg2_pred)\n",
    "\n",
    "score_r2, score_mean_sq_error, score_ex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6002885998931617, 2630.819634458566, 0.600439040791058)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg3_X = reg3.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "reg3_Y = reg3['price']\n",
    "\n",
    "reg3_pred = ridge.predict(reg3_X)\n",
    "\n",
    "\n",
    "score_r2 = r2_score(reg3_Y, reg3_pred)\n",
    "score_mean_sq_error = mean_squared_error(reg3_Y, reg3_pred)\n",
    "score_ex_var = explained_variance_score(reg3_Y, reg3_pred)\n",
    "\n",
    "score_r2, score_mean_sq_error, score_ex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7096766592677992, 2160.6714795252874, 0.7109404250781537)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg4_X = reg4.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "reg4_Y = reg4['price']\n",
    "\n",
    "reg4_pred = ridge.predict(reg4_X)\n",
    "\n",
    "\n",
    "score_r2 = r2_score(reg4_Y, reg4_pred)\n",
    "score_mean_sq_error = mean_squared_error(reg4_Y, reg4_pred)\n",
    "score_ex_var = explained_variance_score(reg4_Y, reg4_pred)\n",
    "\n",
    "score_r2, score_mean_sq_error, score_ex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6429854480300952, 3176.495831020929, 0.6463580085344853)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg5_X = reg5.drop(columns = ['price', 'review_scores_rating', 'zipcode'])\n",
    "reg5_Y = reg5['price']\n",
    "\n",
    "reg5_pred = ridge.predict(reg5_X)\n",
    "\n",
    "\n",
    "score_r2 = r2_score(reg5_Y, reg5_pred)\n",
    "score_mean_sq_error = mean_squared_error(reg5_Y, reg5_pred)\n",
    "score_ex_var = explained_variance_score(reg5_Y, reg5_pred)\n",
    "\n",
    "score_r2, score_mean_sq_error, score_ex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/zhaoxuanyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "tableau_data1 = class1[['latitude', 'longitude']]\n",
    "tableau_data2 = class2[['latitude', 'longitude']]\n",
    "tableau_data3 = class3[['latitude', 'longitude']]\n",
    "tableau_data4 = class4[['latitude', 'longitude']]\n",
    "tableau_data5 = class5[['latitude', 'longitude']]\n",
    "tableau_data6 = class6[['latitude', 'longitude']]\n",
    "tableau_data7 = class7[['latitude', 'longitude']]\n",
    "\n",
    "tableau_data1['cluster'] = 1\n",
    "tableau_data2['cluster'] = 2\n",
    "tableau_data3['cluster'] = 3\n",
    "tableau_data4['cluster'] = 4\n",
    "tableau_data5['cluster'] = 5\n",
    "tableau_data6['cluster'] = 6\n",
    "tableau_data7['cluster'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_data = pd.concat([tableau_data1, tableau_data2, tableau_data3, tableau_data4, tableau_data5, tableau_data6, tableau_data7], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_data.to_csv('tableau_data.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df.to_csv('tableau_data.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
